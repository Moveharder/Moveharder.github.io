import{_ as a,c as s,o as l,a2 as e}from"./chunks/framework.lL4UzoDo.js";const i="/wcdocs/assets/Ollama%E5%88%9B%E5%BB%BA%E5%A4%8D%E5%88%B6%E6%A8%A1%E5%9E%8B%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4.DbxOmWev.png",n="/wcdocs/assets/Ollama%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B%E9%97%AE%E7%AD%94%E6%B5%8B%E8%AF%951.CXKCjoE5.png",t="/wcdocs/assets/Ollama%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B%E9%97%AE%E7%AD%94%E6%B5%8B%E8%AF%952_%E6%97%A0%E5%85%B3%E5%9B%9E%E7%AD%94.Br2Uu-4U.png",A=JSON.parse('{"title":"Ollama Modelfile 自定义模型","description":"","frontmatter":{},"headers":[],"relativePath":"AIGC/ollama/自定义模型.md","filePath":"AIGC/ollama/自定义模型.md","lastUpdated":1739252781000}'),o={name:"AIGC/ollama/自定义模型.md"},p=e(`<h1 id="ollama-modelfile-自定义模型" tabindex="-1">Ollama Modelfile 自定义模型 <a class="header-anchor" href="#ollama-modelfile-自定义模型" aria-label="Permalink to &quot;Ollama Modelfile 自定义模型&quot;">​</a></h1><blockquote><p>Ollama Modelfile 是一个配置文件，用于定义和管理 Ollama 平台上的模型。通过模型文件创建新模型或修改调整现有模型，以应对一些特殊的应用场景。自定义提示嵌入到模型中，修改和调整上下文长度、温度、随机种子、降低无意义程度、增加或减少输出文本的多样性等。（ps：这不是微调，只是调整原来的模型的参数。）</p></blockquote><h2 id="创建modelfile" tabindex="-1">创建Modelfile <a class="header-anchor" href="#创建modelfile" aria-label="Permalink to &quot;创建Modelfile&quot;">​</a></h2><h4 id="核心机制" tabindex="-1">核心机制： <a class="header-anchor" href="#核心机制" aria-label="Permalink to &quot;核心机制：&quot;">​</a></h4><ul><li>将SYSTEM提示预置在对话上下文</li><li>等效于每次对话自动添加预设前缀</li><li>模型权重保持完全不变</li></ul><p>我这里的 <code>Modelfile</code> 是一个名为<code>fty_qa</code> 的无格式文件，需要包含FROM（表示创建模型的源模型），SYSTEM（&quot;&quot;&quot; 注入个人文档内容 &quot;&quot;&quot;），如下：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>FROM deepseek-r1:14b</span></span>
<span class="line"><span>SYSTEM &quot;&quot;&quot;</span></span>
<span class="line"><span>{预设指令}</span></span>
<span class="line"><span>{文档内容}</span></span>
<span class="line"><span>&quot;&quot;&quot;</span></span></code></pre></div><p>提示词增强模版：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 结构化提示模板</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SYSTEM_TEMPLATE</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">[用户档案]</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{personal_data}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">[响应规则]</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">1. 优先引用用户病史</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">2. 避免使用专业术语</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">3. 每次提供2-3个选项</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">[知识库]</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{knowledge_snippets}</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;&quot;&quot;</span></span></code></pre></div><h2 id="创建自定义模型" tabindex="-1">创建自定义模型 <a class="header-anchor" href="#创建自定义模型" aria-label="Permalink to &quot;创建自定义模型&quot;">​</a></h2><p><code>ollama create {新模型名称} -f ./{modelfile名称}</code></p><p><img src="`+i+'" alt="步骤"></p><h3 id="_1-列出当前可用的模型" tabindex="-1">1. 列出当前可用的模型 <a class="header-anchor" href="#_1-列出当前可用的模型" aria-label="Permalink to &quot;1. 列出当前可用的模型&quot;">​</a></h3><ul><li>命令: <code>ollama list</code></li><li>目的: 查看当前系统中已有的模型列表。</li><li>结果: 显示了两个模型，分别是 <code>deepseek-r1:14b</code> 和 <code>QA_Assistant_DS:14b</code>，它们的 ID、大小和修改时间。</li></ul><h3 id="_2-创建新的模型副本" tabindex="-1">2. 创建新的模型副本 <a class="header-anchor" href="#_2-创建新的模型副本" aria-label="Permalink to &quot;2. 创建新的模型副本&quot;">​</a></h3><ul><li>命令: <code>ollama create QA_Assistant_DS:14b -f qa_ds14b</code></li><li>目的: 使用现有的 <code>qa_ds14b</code> 文件作为基础，创建一个名为 <code>QA_Assistant_DS:14b</code> 的新模型。</li><li>过程: <ul><li>系统开始收集模型组件。</li><li>使用现有的层（layer）构建新模型。</li><li>创建新的层并写入清单（manifest）。</li></ul></li><li>结果: 新模型 <code>QA_Assistant_DS:14b</code> 成功创建，并显示其 ID 为 <code>9a662aa0ddf2</code>，大小为 <code>9.0 GB</code>。</li></ul><h3 id="_3-运行新创建的模型" tabindex="-1">3. 运行新创建的模型 <a class="header-anchor" href="#_3-运行新创建的模型" aria-label="Permalink to &quot;3. 运行新创建的模型&quot;">​</a></h3><ul><li>命令: <code>ollama run QA_Assistant_DS:14b</code></li><li>目的: 启动并运行新创建的 <code>QA_Assistant_DS:14b</code> 模型，以便进行交互式对话。</li><li>结果: 模型启动后，可以开始与之进行文本交互，如图中所示的“你是谁？”问题。</li></ul><p>整个过程展示了如何使用 Ollama 工具从现有模型文件创建一个新的模型副本，并成功运行该模型以进行交互。这在需要快速部署或测试不同配置的模型时非常有用。</p><p><img src="'+n+'" alt="问答测试1"><img src="'+t+'" alt="问答测试2"></p>',20),d=[p];function c(h,r,_,u,k,E){return l(),s("div",null,d)}const b=a(o,[["render",c]]);export{A as __pageData,b as default};
